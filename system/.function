# Executable

is-executable() {
    local BIN=`command -v "$1" 2>/dev/null`
    [[ ! $BIN == "" && -x $BIN ]] && true || false
}

is-supported() {
    if [ $# -eq 1 ]; then
        eval $1 > /dev/null 2>&1 && true || false
    else
        eval $1 > /dev/null 2>&1 && echo -n "$2" || echo -n "$3"
    fi
}

# Clean caches

cleanup() {
    is-executable npm && npm cache clean
    is-executable brew && brew cleanup
    is-executable brew && brew cask cleanup
}

# Create a new directory and enter it

mk() {
    mkdir -p "$@" && cd "$@"
}

# Fuzzy find file/dir

ff() {  find . -type f -name "${1}";}
fff() { find . -type f -name "*${1}*";}
fd() {  find . -type d -name "${1}";}
fdf() { find . -type d -name "*${1}*";}

psgrep() {
    ps aux | grep -v " grep $@" | grep "$@" -i;
}

# Show disk usage of current folder, or list with depth

duf() {
    du --max-depth=${1:-0} -c | sort -r -n | awk '{split("K M G",v); s=1; while($1>1024){$1/=1024; s++} print int($1)v[s]"\t"$2}'
}

# Show line, optionally show surrounding lines

line() {
    local line_number=$1
    local lines_around=${2:-0}
    sed -n "`expr $line_number - $lines_around`,`expr $line_number + $lines_around`p"
}

# Show duplicate/unique lines
# Source: https://github.com/ain/.dotfiles/commit/967a2e65a44708449b6e93f87daa2721929cb87a

duplines() {
    sort $1 | uniq -d
}

uniqlines() {
    sort $1 | uniq -u
}

# Pretty print JSON

json() {
    local url=$1
    if [[ "http" == $url[0,4] ]] ; then
        curl --silent $url | python -mjson.tool | pygmentize -O style=monokai -f console256 -g
    else
        cat $url | python -mjson.tool | pygmentize -O style=monokai -f console256 -g
    fi
}

# Extract many types of compress files
# Source: http://nparikh.org/notes/zshrc.txt

extract() {
    if [ -f "$1" ]; then
        case "$1" in
            *.tar.bz2)  tar -jxvf "$1"                        ;;
            *.tar.gz)   tar -zxvf "$1"                        ;;
            *.bz2)      bunzip2 "$1"                          ;;
            *.dmg)      hdiutil mount "$1"                    ;;
            *.gz)       gunzip "$1"                           ;;
            *.tar)      tar -xvf "$1"                         ;;
            *.tbz2)     tar -jxvf "$1"                        ;;
            *.tgz)      tar -zxvf "$1"                        ;;
            *.zip)      unzip "$1"                            ;;
            *.ZIP)      unzip "$1"                            ;;
            *.pax)      cat "$1" | pax -r                     ;;
            *.pax.Z)    uncompress "$1" --stdout | pax -r     ;;
            *.Z)        uncompress "$1"                       ;;
            *)          echo "'$1' cannot be extracted/mounted via extract()" ;;
        esac
    else
        echo "'$1' is not a valid file to extract"
    fi
}

# Check if resource is served compressed

check_compression() {
    curl --write-out 'Size (uncompressed) = %{size_download}\n' --silent --output /dev/null $1
    curl --header 'Accept-Encoding: gzip,deflate,compress' --write-out 'Size (compressed) =   %{size_download}\n' --silent --output /dev/null $1
    curl --head --header 'Accept-Encoding: gzip,deflate' --silent $1 | grep -i "cache\|content\|vary\|expires"
}

# Get gzipped file size

gz() {
	local origsize=$(wc -c < "$1")
	local gzipsize=$(gzip -c "$1" | wc -c)
	local ratio=$(echo "$gzipsize * 100/ $origsize" | bc -l)
	local saved=$(echo "($origsize - $gzipsize) * 100/ $origsize" | bc -l)
	printf "orig: %d bytes\ngzip: %d bytes\nsave: %2.0f%% (%2.0f%%)\n" "$origsize" "$gzipsize" "$saved" "$ratio"
}

# Create a data URL from a file

dataurl() {
    local mimeType=$(file --mime-type "$1" | cut -d ' ' -f2)
    if [[ $mimeType == text/* ]]; then
        mimeType="${mimeType};charset=utf-8"
    fi
    echo "data:${mimeType};base64,$(openssl base64 -in "$1" | tr -d '\n')"
}
